{"cells":[{"cell_type":"markdown","source":["# Lakehouse - incremental data load POC using Spark Change data feed (CDF)\n","#### We will utilise Spark structured streaming to implement our notebook for Dynamics customers data. Spark streaming has some powerful capabilities that handle incremental data with minimal setups. All new changes are read incrementally and merged into a target table"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"fcb521e0-6f6b-40b4-86ca-f72ed6b474d9"},{"cell_type":"code","source":["# Loading the necessary libraries\n","from pyspark.sql import SparkSession\n","from datetime import datetime\n","from dateutil import parser,relativedelta\n","import pyspark.sql.functions as f\n","from pyspark.sql.functions import year, month, dayofmonth, dayofweek, hour, to_date, col, quarter, explode, sequence, expr,current_timestamp,lit\n","from pyspark.sql.types import StructType, StructField, IntegerType, TimestampType, DoubleType, StringType, FloatType, ArrayType, LongType\n","from delta.tables import DeltaTable\n","from notebookutils import mssparkutils\n","spark.conf.set(\"spark.sql.legacy.parquet.int96RebaseModeInWrite\",\"CORRECTED\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":22,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:10:42.6395258Z","session_start_time":null,"execution_start_time":"2024-01-19T05:10:42.9972741Z","execution_finish_time":"2024-01-19T05:10:43.2899982Z","parent_msg_id":"747b5185-f659-417b-9a79-2e55dcdd414f"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 22, Finished, Available)"},"metadata":{}}],"execution_count":14,"metadata":{},"id":"db1d7e16-f17f-48f4-ad53-846237d8c845"},{"cell_type":"markdown","source":["## Define variables\n","##### `delta_load` flag defines whether its full load or incremental load from source.\n","##### To run an initial full load or truncate/reload for a table, set `delta_load` flag as 0 and set the variable with name of the target table (for testing, define new target table). \n","##### To run an incremental load, set `delta_load` flag as 1.\n","##### Define datalake, lakehouse, container and target table. \n","##### <u>Make sure to create the lakehouse before this notebook is run.</u>"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"dce7cfb0-d989-443a-8822-6c59f5cb3b56"},{"cell_type":"code","source":["# 0 for full load and 1 for incremental load\n","delta_load=1\n","#delta_load=0\n","\n","\n","# set path to source table - in our case storage account linked with synapse link\n","path_to_source_table = \"abfss://yourworkspace@onelake.dfs.fabric.microsoft.com/dataverse_xxxxx.Lakehouse/Tables/custtable\"\n","\n","source_table = \"`dataverse_xxxxx`.`custtable`\"\n","\n","\n","#define target variables\n","lakehouse = \"yourlakehouse\" # target lakehouse - create it first if does not exist\n","\n","\n","target_table = \"customer_silver\" # target table\n","lakehouse_targettable = lakehouse + \".\" + target_table\n","path_to_target_table = \"Files/clickstreamdata/\"+ target_table # to help create a DeltaTable object for merge\n","\n","\n","# set temp table and its path. This table holds incremental data before merging into target table\n","temp_table = \"customer_silver_temp\"\n","lakehouse_temptable = lakehouse + \".\" + temp_table\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":41,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:18:11.1046548Z","session_start_time":null,"execution_start_time":"2024-01-19T05:18:11.4855564Z","execution_finish_time":"2024-01-19T05:18:11.787986Z","parent_msg_id":"4aad7356-ab1e-4c51-97da-a819acd667b7"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 41, Finished, Available)"},"metadata":{}}],"execution_count":33,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"1db95e1b-27a0-4c84-8e78-bc805af00bed"},{"cell_type":"markdown","source":["## Enable CDF on table\n","#### You can retrieve detailed information about a Delta table (for example, number of files, data size) using DESCRIBE DETAIL. We confirm the property delta.enableChangeDataFeed is indeed enabled."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"890cdbc2-1c15-4647-9aa7-863719a37551"},{"cell_type":"code","source":["# run only once to enable CDF on the table\n","'''\n","if delta_load == 0:\n","    spark.sql(f\"ALTER TABLE {source_table} SET TBLPROPERTIES ('delta.enableChangeDataFeed'='true')\")\n","    df = spark.sql(f\"DESCRIBE DETAIL {source_table}\")\n","    display (df.limit(10))\n","'''    \n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":24,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:10:43.0129336Z","session_start_time":null,"execution_start_time":"2024-01-19T05:10:44.4883308Z","execution_finish_time":"2024-01-19T05:10:44.7956012Z","parent_msg_id":"2afcac4f-ebb4-4a56-bcce-4e168e07554f"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 24, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"'\\nif delta_load == 0:\\n    spark.sql(f\"ALTER TABLE {source_table} SET TBLPROPERTIES (\\'delta.enableChangeDataFeed\\'=\\'true\\')\")\\n    df = spark.sql(f\"DESCRIBE DETAIL {source_table}\")\\n    display (df.limit(10))\\n'"},"metadata":{}}],"execution_count":16,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{},"collapsed":false},"id":"babdc914-d6ef-4471-88ac-3152e4096693"},{"cell_type":"markdown","source":["## Read data \n","#### Next we need to retrieve changed data from change data feed folders based on starting version and ending version. We use Describe history to get the latest version of the commit on source table. Describe history has information on the operations, user, timestamp, and so on for each write to a Delta table. The operations are returned in reverse chronological order. By default table history is retained for 30 days.\n","\n","#### The three columns _change_type, _commit_version and _commit_timestamp come due to CDF being enabled on the source table. _change_type can be insert or delete or update_preimage or update_postimage. We will remove records with values update_preimage as these are before update and not needed for merge. _commit_version is an ever increasing number and crucial for our where clause to read only the changed data. More info: https://docs.delta.io/latest/delta-change-data-feed.html#what-is-the-schema-for-the-change-data-feed"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e8887f34-40ad-43ab-babb-e76b4d55df5d"},{"cell_type":"code","source":["# incremental load\n","\n","if delta_load == 1:\n","\n","  #Retrieve the latest version of the change data feed table, we read only latest record\n","  source_df = spark.sql (f\"DESCRIBE HISTORY {source_table} LIMIT 1\")\n","  max_version = source_df.agg({\"version\": \"max\"}).collect()[0][0]\n","\n","  #Retrieve the last commit version from target table. We can also use the temp table to get this value as temp table is much smaller\n","  target_df = spark.sql(f\"SELECT _commit_version FROM {lakehouse_targettable}\")\n","  last_commit_version = target_df.agg({\"_commit_version\": \"max\"}).collect()[0][0]\n","\n","  if max_version == last_commit_version:\n","    mssparkutils.notebook.exit(\"Aborting as condition not met. Further tasks will be skipped\")\n","\n","  start_version = last_commit_version + 1 # we want to read from after last commited version\n","\n","# filters for starting and ending versions give us incremental data, both are included\n","  cdf_table_df = spark.read.format(\"delta\") \\\n","    .option(\"readChangeFeed\", \"true\") \\\n","    .option(\"startingVersion\", start_version) \\\n","    .option(\"endingVersion\", max_version) \\\n","    .table(source_table)\n","\n","# full load\n","else:\n","\n"," # we will read dataframe from source file and not use CDF file\n","  cdf_table_df = spark.read.format('delta') \\\n","  .table(source_table)\n","\n","\n","  #after enabling the change data feed for delta table\n","  #Since we want to use Change Data feed, we need to capture the version number, and use it as watermark for incremental\n","  df = spark.sql (f\"DESCRIBE HISTORY {source_table}\")\n","  max_version = df.agg({\"version\": \"max\"}).collect()[0][0]\n","     \n","  cdf_table_df = cdf_table_df.withColumn(\"_commit_version\", lit(max_version))\n","  cdf_table_df = cdf_table_df.withColumn(\"_change_type\", lit('insert'))\n","  cdf_table_df = cdf_table_df.withColumn(\"_commit_timestamp\", lit(current_timestamp()))\n","  cdf_table_df = cdf_table_df.withColumn(\"_loadedtimestamp\", lit(current_timestamp()))\n","\n","  "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":25,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:10:43.2364707Z","session_start_time":null,"execution_start_time":"2024-01-19T05:10:45.2337715Z","execution_finish_time":"2024-01-19T05:11:01.68822Z","parent_msg_id":"6afafa96-b706-4dcd-8a5e-f3b74c5fad42"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 25, Finished, Available)"},"metadata":{}}],"execution_count":17,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"ff76b0aa-dbf5-4860-9326-52e9d9e42144"},{"cell_type":"markdown","source":["## De-duplication and extract columns\n","##### Remove any duplicates, read only latest. We will remove records with values update_preimage as these are before update and not needed for merge."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"ff450b70-b6df-41bd-b5da-6cefe4302e2c"},{"cell_type":"code","source":["# incremental load\n","if delta_load == 1:\n","\n","    cdf_table_df.createOrReplaceTempView(\"cdf_table\")\n","    # We also will get latest version of the records\n","    cdf_table_df = spark.sql(\"\"\"\n","                            select * \n","                            from (\n","                                    select *, row_number () over (partition by Id order by _commit_version desc) as Row_id \n","                                    from cdf_table\n","                                    WHERE _change_type !='update_preimage'\n","                                ) sub2\n","                                where sub2.Row_id =1\n","                                \"\"\")\n","    cdf_table_df = cdf_table_df.select(col('Id'), col('accountnum'), col('custgroup'), col('currency'), col('IsDelete'), col('_commit_version'), col('_change_type'), col('_commit_timestamp'))\n","\n","    cdf_table_df = cdf_table_df.withColumn(\"_loadedtimestamp\", lit(current_timestamp()))\n","\n","    cdf_table_df = cdf_table_df.withColumnRenamed('accountnum', 'CustomerId')\n","    cdf_table_df = cdf_table_df.withColumnRenamed('custgroup', 'CustomerGroup')\n","    cdf_table_df = cdf_table_df.withColumnRenamed('currency', 'Currency')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":26,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:10:43.5257631Z","session_start_time":null,"execution_start_time":"2024-01-19T05:11:02.1698529Z","execution_finish_time":"2024-01-19T05:11:02.464371Z","parent_msg_id":"bf3259b0-468b-4af7-aa7d-3deed37cdf12"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 26, Finished, Available)"},"metadata":{}}],"execution_count":18,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"042fc5ac-b4f9-4653-8106-a8deef7c0064"},{"cell_type":"markdown","source":["## Write the temp table\n","#####  We write in Overwrite mode so previous changes are discarded and we only retain new batch of incremental data. "],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"95733c91-f574-45fe-9e81-7fee69cf0d0f"},{"cell_type":"code","source":["# Creating the lake database if it does not exist\n","'''\n","spark.sql (f\"\"\"\n","CREATE DATABASE IF NOT EXISTS {lakehouse}\n","\"\"\")\n","'''"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":27,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:10:43.7549609Z","session_start_time":null,"execution_start_time":"2024-01-19T05:11:02.8662061Z","execution_finish_time":"2024-01-19T05:11:03.1608236Z","parent_msg_id":"e1c397c6-ba8f-4ee8-8e01-76032bac0f40"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 27, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"'\\nspark.sql (f\"\"\"\\nCREATE DATABASE IF NOT EXISTS {lakehouse}\\n\"\"\")\\n'"},"metadata":{}}],"execution_count":19,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{}},"id":"6e600147-2638-4b52-b55f-6429836d6e27"},{"cell_type":"code","source":["# at this stage, you can write the df to a temp table for analysis, enrichment\n","cdf_table_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(lakehouse_temptable)\n","\n","display(cdf_table_df.limit(10))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":28,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:10:43.97241Z","session_start_time":null,"execution_start_time":"2024-01-19T05:11:03.6188195Z","execution_finish_time":"2024-01-19T05:11:13.6252487Z","parent_msg_id":"d54f3110-d8a0-4c22-8564-10dd5af7d8a1"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 28, Finished, Available)"},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.synapse.widget-view+json":{"widget_id":"3740c6ab-5269-4f61-a9ea-efa9e1257c1a","widget_type":"Synapse.DataFrame"},"text/plain":"SynapseWidget(Synapse.DataFrame, 3740c6ab-5269-4f61-a9ea-efa9e1257c1a)"},"metadata":{}}],"execution_count":20,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"5f16417c-154c-4f92-afb4-8f8d0304b73a"},{"cell_type":"code","source":["#df = spark.sql(f\"SELECT * FROM {lakehouse_temptable}\")\n","#display(df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":29,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:10:44.3326321Z","session_start_time":null,"execution_start_time":"2024-01-19T05:11:14.0668828Z","execution_finish_time":"2024-01-19T05:11:14.3579397Z","parent_msg_id":"9bf6f13b-eb57-4399-a0ca-1a67678ce6ac"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 29, Finished, Available)"},"metadata":{}}],"execution_count":21,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"0f412937-2069-4f3b-89b4-bf2cb6deecc7"},{"cell_type":"code","source":["#df = spark.sql(f\"SELECT count(*) FROM {lakehouse_temptable}\")\n","#display(df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":30,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:10:44.6122129Z","session_start_time":null,"execution_start_time":"2024-01-19T05:11:14.8062304Z","execution_finish_time":"2024-01-19T05:11:15.1062402Z","parent_msg_id":"281f10d4-fffb-4146-a180-53adde3f8b69"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 30, Finished, Available)"},"metadata":{}}],"execution_count":22,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"64930efb-bf34-43b7-a693-85d03e0de278"},{"cell_type":"markdown","source":["## Quality Checks\n","##### Here we are validating that certain columns in the dataframe are unique and not null. The validate function will check all the expectations we've set up and return the results.\n","##### For example, we want to make sure CustomerId is unique, this can be challenging as you may get multiple copies of same Id when it comes to updates, which can break our merge. \n","##### We use an open source library called Great expectations. It has many more capabilities, you can find here. https://learn.microsoft.com/en-us/fabric/data-science/tutorial-great-expectations"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"93c6d041-052d-46a1-bbf6-8ed263c4bd37"},{"cell_type":"code","source":["# install libraries and then comment it before next run\n","%pip install semantic-link great-expectations great_expectations_experimental great_expectations_zipcode_expectations\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":31,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:10:44.8440941Z","session_start_time":null,"execution_start_time":"2024-01-19T05:11:15.6350392Z","execution_finish_time":"2024-01-19T05:11:15.9357176Z","parent_msg_id":"a7f7ac4d-c0a1-4966-b6bd-21190e8c11f4"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 31, Finished, Available)"},"metadata":{}}],"execution_count":23,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"490db284-48d2-4c64-9e1c-b952eca8e05d"},{"cell_type":"code","source":["import great_expectations as ge\n","import great_expectations.dataset.sparkdf_dataset as sd\n","\n","# Convert Spark DataFrame to Great Expectations Dataset\n","ge_df = ge.dataset.SparkDFDataset(cdf_table_df)\n","\n","# Define Expectations\n","\n","# Not null \n","ge_df.expect_column_values_to_not_be_null('CustomerGroup')\n","ge_df.expect_column_values_to_not_be_null('Currency')\n","\n","# Unique\n","ge_df.expect_column_values_to_be_unique('CustomerId')\n","\n","\n","# Validate Expectations\n","results = ge_df.validate()\n","\n","print(results)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":32,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:10:45.0691715Z","session_start_time":null,"execution_start_time":"2024-01-19T05:11:16.7450019Z","execution_finish_time":"2024-01-19T05:11:24.8364125Z","parent_msg_id":"da452a21-01ec-417e-9fad-b6297476e850"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 32, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{\n  \"success\": true,\n  \"results\": [\n    {\n      \"success\": true,\n      \"expectation_config\": {\n        \"expectation_type\": \"expect_column_values_to_not_be_null\",\n        \"kwargs\": {\n          \"column\": \"CustomerGroup\",\n          \"result_format\": \"BASIC\"\n        },\n        \"meta\": {}\n      },\n      \"result\": {\n        \"element_count\": 3,\n        \"unexpected_count\": 0,\n        \"unexpected_percent\": 0.0,\n        \"unexpected_percent_total\": 0.0,\n        \"partial_unexpected_list\": []\n      },\n      \"meta\": {},\n      \"exception_info\": {\n        \"raised_exception\": false,\n        \"exception_message\": null,\n        \"exception_traceback\": null\n      }\n    },\n    {\n      \"success\": true,\n      \"expectation_config\": {\n        \"expectation_type\": \"expect_column_values_to_not_be_null\",\n        \"kwargs\": {\n          \"column\": \"Currency\",\n          \"result_format\": \"BASIC\"\n        },\n        \"meta\": {}\n      },\n      \"result\": {\n        \"element_count\": 3,\n        \"unexpected_count\": 0,\n        \"unexpected_percent\": 0.0,\n        \"unexpected_percent_total\": 0.0,\n        \"partial_unexpected_list\": []\n      },\n      \"meta\": {},\n      \"exception_info\": {\n        \"raised_exception\": false,\n        \"exception_message\": null,\n        \"exception_traceback\": null\n      }\n    },\n    {\n      \"success\": true,\n      \"expectation_config\": {\n        \"expectation_type\": \"expect_column_values_to_be_unique\",\n        \"kwargs\": {\n          \"column\": \"CustomerId\",\n          \"result_format\": \"BASIC\"\n        },\n        \"meta\": {}\n      },\n      \"result\": {\n        \"element_count\": 3,\n        \"missing_count\": 0,\n        \"missing_percent\": 0.0,\n        \"unexpected_count\": 0,\n        \"unexpected_percent\": 0.0,\n        \"unexpected_percent_total\": 0.0,\n        \"unexpected_percent_nonmissing\": 0.0,\n        \"partial_unexpected_list\": []\n      },\n      \"meta\": {},\n      \"exception_info\": {\n        \"raised_exception\": false,\n        \"exception_message\": null,\n        \"exception_traceback\": null\n      }\n    }\n  ],\n  \"evaluation_parameters\": {},\n  \"statistics\": {\n    \"evaluated_expectations\": 3,\n    \"successful_expectations\": 3,\n    \"unsuccessful_expectations\": 0,\n    \"success_percent\": 100.0\n  },\n  \"meta\": {\n    \"great_expectations_version\": \"0.18.8\",\n    \"expectation_suite_name\": \"default\",\n    \"run_id\": {\n      \"run_name\": null,\n      \"run_time\": \"2024-01-19T05:11:21.078899+00:00\"\n    },\n    \"batch_kwargs\": {\n      \"ge_batch_id\": \"2c9815a0-b689-11ee-87e0-00224808c7c5\"\n    },\n    \"batch_markers\": {},\n    \"batch_parameters\": {},\n    \"validation_time\": \"20240119T051121.078750Z\",\n    \"expectation_suite_meta\": {\n      \"great_expectations_version\": \"0.18.8\"\n    }\n  }\n}\n"]}],"execution_count":24,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"4f35ec1e-e084-4beb-96b6-add1103612b8"},{"cell_type":"markdown","source":["## Enrich your silver\n","##### At this stage, you have a deduped incremental data. You can enrich it further by making joins with other tables, or picking out columns you are interested in and discarding rest. Next, we do the merge with the target silver table. This same process of picking out incremental changes using CDF folders can happen for your gold tables."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"77136e0e-ac6e-4344-bc6a-659fe796975a"},{"cell_type":"markdown","source":["## Merge\n","##### We use Delta lake merge function, to either update, delete or insert. Note the condition uses Id and IsDelete. The deleted records come with IsDelete as true and we use that condition to delete them from target. More info: https://docs.delta.io/latest/delta-update.html"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5598c4ff-e385-479b-a3cc-9a1ddf2a7001"},{"cell_type":"code","source":["if delta_load == 0:\n","\n","    #first time write, no merge needed, you can either save the df as target or enriched temp table as target\n","    cdf_table_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(lakehouse + \".\" + target_table)\n","\n","else:\n","\n","    targetTable = DeltaTable.forPath(spark, path_to_target_table)\n","    (\n","    # Execute merge\n","    targetTable.alias(\"target\").merge(\n","        cdf_table_df.alias(\"source\"),\n","        \"source.Id = target.Id\"\n","\n","    )\n","    .whenMatchedDelete(condition = \"source.IsDelete = 'true'\") \n","    .whenMatchedUpdateAll()\n","    .whenNotMatchedInsertAll()\n","    .execute()\n","    )"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":42,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:18:17.2344019Z","session_start_time":null,"execution_start_time":"2024-01-19T05:18:17.5782322Z","execution_finish_time":"2024-01-19T05:18:24.0257755Z","parent_msg_id":"767d68d3-1c36-41b8-9f82-0b8dbae1ae57"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 42, Finished, Available)"},"metadata":{}}],"execution_count":34,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"dc98008c-de79-493b-b8ea-74f283be537f"},{"cell_type":"markdown","source":["## Time travel\n","#### You can use versions and timestamps feature of change data feed files to do time travel and know data values in the past. For more info, read: https://delta.io/blog/2023-02-01-delta-lake-time-travel/"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2f34ac8f-2925-4339-bc72-8ef77bea5a17"},{"cell_type":"code","source":["#Retrieve the latest version of the change data feed table, we read only latest record\n","\n","target_df = spark.sql(f\"SELECT _commit_version FROM {lakehouse_temptable}\")\n","new_last_commit_version = target_df.agg({\"_commit_version\": \"max\"}).collect()[0][0]\n","\n","new_last_commit_version\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":43,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:21:45.8243795Z","session_start_time":null,"execution_start_time":"2024-01-19T05:21:46.2682796Z","execution_finish_time":"2024-01-19T05:21:48.2465693Z","parent_msg_id":"6a780354-45eb-4385-ac79-a092a6f4b9af"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 43, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":79,"data":{"text/plain":"4"},"metadata":{}}],"execution_count":35,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"2ce9a246-3c0c-4a91-90f2-a1ebc27b39a1"},{"cell_type":"code","source":["custdf = spark.sql(f\"SELECT custGroup FROM {source_table} VERSION AS OF {new_last_commit_version} where accountnum == '004003' \")\n","\n","display (custdf.limit(5))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":44,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:21:45.9712123Z","session_start_time":null,"execution_start_time":"2024-01-19T05:21:48.6540649Z","execution_finish_time":"2024-01-19T05:21:52.33312Z","parent_msg_id":"fb692c93-dc22-4996-9181-26a69a3bf7cc"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 44, Finished, Available)"},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.synapse.widget-view+json":{"widget_id":"c460cf5c-9d75-4c89-9ca7-71fd573269c8","widget_type":"Synapse.DataFrame"},"text/plain":"SynapseWidget(Synapse.DataFrame, c460cf5c-9d75-4c89-9ca7-71fd573269c8)"},"metadata":{}}],"execution_count":36,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"84c2e4dd-6799-4473-a8a1-1e6d86e16945"},{"cell_type":"code","source":["custdf = spark.sql(f\"SELECT custGroup FROM {source_table} VERSION AS OF {last_commit_version} where accountnum == '004003' \")\n","\n","display (custdf.limit(5))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":45,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:21:46.1181632Z","session_start_time":null,"execution_start_time":"2024-01-19T05:21:52.7664956Z","execution_finish_time":"2024-01-19T05:21:55.2667814Z","parent_msg_id":"7d9985fc-83c0-4f09-9e0f-8fbdaa0bc08e"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 45, Finished, Available)"},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.synapse.widget-view+json":{"widget_id":"11b72cc4-1919-4b2b-8727-7638eb1744c1","widget_type":"Synapse.DataFrame"},"text/plain":"SynapseWidget(Synapse.DataFrame, 11b72cc4-1919-4b2b-8727-7638eb1744c1)"},"metadata":{}}],"execution_count":37,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"85f603dc-ed33-4cd4-97ae-7a2a8f21d0ff"},{"cell_type":"code","source":["'''\n","# filters specific version\n","cdf_table_df_new = spark.read.format(\"delta\") \\\n","    .option(\"versionAsOf\", new_last_commit_version) \\\n","    .table(source_table)\n","\n","display (new_last_commit_version)\n","display (cdf_table_df_new.limit(10))\n","'''\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":46,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:21:46.3157322Z","session_start_time":null,"execution_start_time":"2024-01-19T05:21:55.6698689Z","execution_finish_time":"2024-01-19T05:21:55.977609Z","parent_msg_id":"eeb5de32-2207-4e1c-9e32-14491d5e4d01"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 46, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":88,"data":{"text/plain":"'\\n# filters specific version\\ncdf_table_df_new = spark.read.format(\"delta\")     .option(\"versionAsOf\", new_last_commit_version)     .table(source_table)\\n\\ndisplay (new_last_commit_version)\\ndisplay (cdf_table_df_new.limit(10))\\n'"},"metadata":{}}],"execution_count":38,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"22049ae8-931d-4c96-9efb-7bea57c6991e"},{"cell_type":"code","source":["'''\n","cdf_table_df_old = spark.read.format(\"delta\") \\\n","    .option(\"versionAsOf\", last_commit_version) \\\n","    .table(source_table)\n","\n","\n","display (last_commit_version)\n","display (cdf_table_df_old.limit(10))\n","'''"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":47,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:21:46.5456327Z","session_start_time":null,"execution_start_time":"2024-01-19T05:21:56.8164322Z","execution_finish_time":"2024-01-19T05:21:57.1225936Z","parent_msg_id":"7c8da29c-904b-4365-8636-af55bca6a4b2"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 47, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":91,"data":{"text/plain":"'\\ncdf_table_df_old = spark.read.format(\"delta\")     .option(\"versionAsOf\", last_commit_version)     .table(source_table)\\n\\n\\ndisplay (last_commit_version)\\ndisplay (cdf_table_df_old.limit(10))\\n'"},"metadata":{}}],"execution_count":39,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"50d750d2-22cf-46d0-98ab-6267c7186caf"},{"cell_type":"markdown","source":["## Cleanup with Vacuum command\n","##### Remove old data in the temp table by using the Vacuum command, which physically removes files from storage that are older than the retention period. This saves storage costs. You can consider using vaccum for source delta lake folders (Synapse link folders) as well once data is read. You will lose ability to time travel if you use vaccum command so you should plan your retention based on business needs. \n","More info: https://delta.io/blog/remove-files-delta-lake-vacuum-command/"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"02d04b6c-b62e-40c4-8f9c-d9c0e93379a2"},{"cell_type":"code","source":["#spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", \"false\")\n","#spark.sql(f\"VACUUM {lakehouse_temptable} RETAIN 0 HOURS\").show(truncate=False)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"22d61851-fb53-4466-83c8-bd4a79ee364d","statement_id":48,"state":"finished","livy_statement_state":"available","queued_time":"2024-01-19T05:21:46.8625814Z","session_start_time":null,"execution_start_time":"2024-01-19T05:21:57.5183984Z","execution_finish_time":"2024-01-19T05:21:57.8364676Z","parent_msg_id":"7517e1e5-abbf-40b6-a038-8c8e868c35a3"},"text/plain":"StatementMeta(, 22d61851-fb53-4466-83c8-bd4a79ee364d, 48, Finished, Available)"},"metadata":{}}],"execution_count":40,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"9e501417-8d57-4663-9136-f2bbc6ef66ea"},{"cell_type":"markdown","source":["## Conclusion\n","##### The notebook demonstrates a POC of achieving incremental pipeline for data loading at scale using Delta lake change data feed feature. CDF offers a powerful mechansim to load changed data."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"a2ac013f-0871-41f1-83da-b694ec1c91ba"}],"metadata":{"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python"},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"description":null,"synapse_widget":{"version":"0.1","state":{"3740c6ab-5269-4f61-a9ea-efa9e1257c1a":{"type":"Synapse.DataFrame","sync_state":{"table":{"rows":[{"0":"0000286b-0000-0000-d806-014105000000","1":"100001","2":"3","3":"USD","4":"NULL","5":"4","6":"update_postimage","7":"2024-01-19 03:48:01.681","8":"2024-01-19 05:11:11.590838","index":1},{"0":"0000286b-0000-0000-f0b3-000010000000","1":"005327","2":"10","3":"USD","4":"NULL","5":"4","6":"update_postimage","7":"2024-01-19 03:48:01.681","8":"2024-01-19 05:11:11.590838","index":2},{"0":"0000286b-0000-0000-f1b3-000010000000","1":"005328","2":"10","3":"USD","4":"NULL","5":"4","6":"insert","7":"2024-01-19 03:48:01.681","8":"2024-01-19 05:11:11.590838","index":3}],"schema":[{"key":"0","name":"Id","type":"string"},{"key":"1","name":"CustomerId","type":"string"},{"key":"2","name":"CustomerGroup","type":"string"},{"key":"3","name":"Currency","type":"string"},{"key":"4","name":"IsDelete","type":"boolean"},{"key":"5","name":"_commit_version","type":"bigint"},{"key":"6","name":"_change_type","type":"string"},{"key":"7","name":"_commit_timestamp","type":"timestamp"},{"key":"8","name":"_loadedtimestamp","type":"timestamp"}],"truncated":false},"isSummary":false,"language":"scala"},"persist_state":{"view":{"type":"details","tableOptions":{},"chartOptions":{"chartType":"bar","categoryFieldKeys":["0"],"seriesFieldKeys":["5"],"aggregationType":"sum","isStacked":false,"binsNumber":10,"wordFrequency":"-1"}}}},"c460cf5c-9d75-4c89-9ca7-71fd573269c8":{"type":"Synapse.DataFrame","sync_state":{"table":{"rows":[{"0":"20","index":1}],"schema":[{"key":"0","name":"custGroup","type":"string"}],"truncated":false},"isSummary":false,"language":"scala"},"persist_state":{"view":{"type":"details","tableOptions":{},"chartOptions":{"chartType":"bar","categoryFieldKeys":["0"],"seriesFieldKeys":["0"],"aggregationType":"count","isStacked":false,"binsNumber":10,"wordFrequency":"-1"}}}},"11b72cc4-1919-4b2b-8727-7638eb1744c1":{"type":"Synapse.DataFrame","sync_state":{"table":{"rows":[{"0":"20","index":1}],"schema":[{"key":"0","name":"custGroup","type":"string"}],"truncated":false},"isSummary":false,"language":"scala"},"persist_state":{"view":{"type":"details","tableOptions":{},"chartOptions":{"chartType":"bar","categoryFieldKeys":["0"],"seriesFieldKeys":["0"],"aggregationType":"count","isStacked":false,"binsNumber":10,"wordFrequency":"-1"}}}}}},"save_output":true,"spark_compute":{"compute_id":"/trident/default"},"trident":{"lakehouse":{"known_lakehouses":[{"id":"9e8f8d12-8410-4ea7-a846-36bb39cd339e"}],"default_lakehouse":"9e8f8d12-8410-4ea7-a846-36bb39cd339e","default_lakehouse_name":"retailclickstream","default_lakehouse_workspace_id":"cb54ad30-999a-45f7-96d5-a280b177a440"}}},"nbformat":4,"nbformat_minor":5}