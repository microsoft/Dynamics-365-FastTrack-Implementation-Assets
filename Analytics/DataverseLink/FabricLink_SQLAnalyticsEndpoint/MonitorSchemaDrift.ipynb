{"cells":[{"cell_type":"code","source":["# Step 0: Setup\n","from pyspark.sql.functions import coalesce, lit, col, when, trim\n","from datetime import datetime\n","\n","# Timestamped version string\n","now = datetime.now()\n","version_str = now.strftime('%Y%m%d_%H%M')  # e.g. '20250822_0841'\n","timestamp_str = now.strftime('%Y-%m-%d %H:%M:%S')\n","\n","# Define tables to track# \n","# ‚úÖ Manual list for testing\n","tables = [\"account\", \"salestable\", \"salesline\"]\n","\n","# üîÑ Uncomment this line to use all managed tables in the Lakehouse\n","# tables = [table.name for table in spark.catalog.listTables() if table.tableType == 'MANAGED']\n","\n","\n","# Step 1: Capture current schema snapshot\n","\n","all_schemas = []\n","\n","for table_name in tables:\n","    try:\n","        df = spark.read.table(table_name)\n","        schema_info = [(table_name, field.name, field.dataType.simpleString(), field.nullable) for field in df.schema.fields]\n","        all_schemas.extend(schema_info)\n","    except Exception as e:\n","        print(f\"‚ö†Ô∏è Skipping {table_name}: {e}\")\n","\n","schema_df = spark.createDataFrame(all_schemas, [\"table_name\", \"column_name\", \"data_type\", \"is_nullable\"])\n","schema_df = schema_df.withColumn(\"snapshot_version\", lit(version_str))\n","schema_df = schema_df.withColumn(\"snapshot_timestamp\", lit(timestamp_str))\n","\n","\n","# Step 2: Save snapshot to lakehouse\n","schema_df.write.mode(\"append\").saveAsTable(\"lakehouse_schema_snapshots\")\n","print(f\"‚úÖ Snapshot saved with version {version_str} at {timestamp_str}\")\n","\n","\n","# Get distinct versions sorted descending\n","versions_df = spark.sql(\"\"\"\n","    SELECT DISTINCT snapshot_version \n","    FROM lakehouse_schema_snapshots\n","    ORDER BY snapshot_version DESC\n","\"\"\")\n","\n","# Collect top two versions\n","versions = [row[\"snapshot_version\"] for row in versions_df.limit(2).collect()]\n","\n","if len(versions) < 2:\n","    raise ValueError(\"‚ùå Not enough versions to compare. Need at least two snapshots.\")\n","\n","version_b = versions[0]  # Most recent\n","version_a = versions[1]  # Previous\n","\n","print(f\"‚úÖ Most recent snapshot version {version_b} previous snapshot version {version_a}\")\n","\n","\n","# Step 3: Load two versions for comparison\n","\n","# version_a = '20250822_0830'  # Replace with earlier version\n","# version_b = version_str      # Current version\n","\n","df_old = spark.sql(f\"\"\"\n","    SELECT table_name, column_name, data_type, is_nullable \n","    FROM lakehouse_schema_snapshots \n","    WHERE snapshot_version = '{version_a}'\n","\"\"\")\n","\n","df_new = spark.sql(f\"\"\"\n","    SELECT table_name, column_name, data_type, is_nullable \n","    FROM lakehouse_schema_snapshots \n","    WHERE snapshot_version = '{version_b}'\n","\"\"\")\n","\n","\n","# Step 4: Detect drift via full outer join\n","\n","drift_df = df_new.alias(\"new\").join(\n","    df_old.alias(\"old\"),\n","    on=[\"table_name\", \"column_name\"],\n","    how=\"full_outer\"\n",").select(\n","    coalesce(col(\"new.table_name\"), col(\"old.table_name\")).alias(\"table_name\"),\n","    coalesce(col(\"new.column_name\"), col(\"old.column_name\")).alias(\"column_name\"),\n","    col(\"old.data_type\").alias(\"old_type\"),\n","    col(\"new.data_type\").alias(\"new_type\"),\n","    col(\"old.is_nullable\").alias(\"old_nullable\"),\n","    col(\"new.is_nullable\").alias(\"new_nullable\")\n",").withColumn(\"change_type\", when(col(\"old_type\").isNull(), \"added\")\n","    .when(col(\"new_type\").isNull(), \"removed\")\n","    .when(trim(col(\"old_type\")) != trim(col(\"new_type\")), \"type_changed\")\n","    .when(trim(col(\"old_nullable\")) != trim(col(\"new_nullable\")), \"nullability_changed\")\n","    .otherwise(\"unchanged\"))\n","\n","\n","# Step 5: Display or Save drift report\n","drift_df.write.mode(\"overwrite\").saveAsTable(\"lakehouse_schema_drift_log\")\n","\n","drift_df_filtered = drift_df.filter(col(\"change_type\") != \"unchanged\")\n","\n","summary_df = drift_df_filtered.groupBy(\"table_name\", \"change_type\").count().orderBy(\"table_name\")\n","summary_df.show(truncate=False)\n","\n","drift_df_filtered.show(truncate=False)\n","\n","drift_df.show(truncate=False)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"e003e68b-0898-478a-b5bc-25281ef3378f","normalized_state":"finished","queued_time":"2025-09-02T18:26:53.8407158Z","session_start_time":null,"execution_start_time":"2025-09-02T18:26:53.8420457Z","execution_finish_time":"2025-09-02T18:27:49.6577619Z","parent_msg_id":"4fd816da-33ea-447c-9f1b-602d0dc4080d"},"text/plain":"StatementMeta(, e003e68b-0898-478a-b5bc-25281ef3378f, 10, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Snapshot saved with version 20250902_1826 at 2025-09-02 18:26:53\n‚úÖ Most recent snapshot version 20250902_1826 previous snapshot version 20250902_1819\n+----------+-----------+-----+\n|table_name|change_type|count|\n+----------+-----------+-----+\n+----------+-----------+-----+\n\n+----------+-----------+--------+--------+------------+------------+-----------+\n|table_name|column_name|old_type|new_type|old_nullable|new_nullable|change_type|\n+----------+-----------+--------+--------+------------+------------+-----------+\n+----------+-----------+--------+--------+------------+------------+-----------+\n\n+----------+------------------------------+---------+---------+------------+------------+-----------+\n|table_name|column_name                   |old_type |new_type |old_nullable|new_nullable|change_type|\n+----------+------------------------------+---------+---------+------------+------------+-----------+\n|account   |Id                            |string   |string   |true        |true        |unchanged  |\n|salesline |Id                            |string   |string   |true        |true        |unchanged  |\n|salestable|Id                            |string   |string   |true        |true        |unchanged  |\n|account   |IsDelete                      |boolean  |boolean  |true        |true        |unchanged  |\n|salesline |IsDelete                      |boolean  |boolean  |true        |true        |unchanged  |\n|salestable|IsDelete                      |boolean  |boolean  |true        |true        |unchanged  |\n|account   |PartitionId                   |string   |string   |true        |true        |unchanged  |\n|salesline |PartitionId                   |string   |string   |true        |true        |unchanged  |\n|salestable|PartitionId                   |string   |string   |true        |true        |unchanged  |\n|account   |SinkCreatedOn                 |timestamp|timestamp|true        |true        |unchanged  |\n|salesline |SinkCreatedOn                 |timestamp|timestamp|true        |true        |unchanged  |\n|salestable|SinkCreatedOn                 |timestamp|timestamp|true        |true        |unchanged  |\n|account   |SinkModifiedOn                |timestamp|timestamp|true        |true        |unchanged  |\n|salesline |SinkModifiedOn                |timestamp|timestamp|true        |true        |unchanged  |\n|salestable|SinkModifiedOn                |timestamp|timestamp|true        |true        |unchanged  |\n|account   |accountcategorycode           |bigint   |bigint   |true        |true        |unchanged  |\n|account   |accountclassificationcode     |bigint   |bigint   |true        |true        |unchanged  |\n|account   |accountid                     |string   |string   |true        |true        |unchanged  |\n|salesline |accountingdistributiontemplate|bigint   |bigint   |true        |true        |unchanged  |\n|salestable|accountingdistributiontemplate|bigint   |bigint   |true        |true        |unchanged  |\n+----------+------------------------------+---------+---------+------------+------------+-----------+\nonly showing top 20 rows\n\n"]}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"60592dc9-3901-4f26-b7c3-75d75d718044"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"a552604a-f70a-4d5b-8426-1a6eaebf2c2b","known_lakehouses":[{"id":"a552604a-f70a-4d5b-8426-1a6eaebf2c2b"}],"default_lakehouse_name":"dataverse_stkopudeus_cds2_workspace_unqd5b0fcea537ef0118589000d3a357","default_lakehouse_workspace_id":"f10120cf-22d3-42b9-aca8-d989b9ce46bf"}}},"nbformat":4,"nbformat_minor":5}